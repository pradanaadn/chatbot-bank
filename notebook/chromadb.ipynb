{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAgedLQmOOyikNiR3R6ZkhKJa4JgHJ14G4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0312f322-05fe-46d1-adb0-72dda5f187c8',\n",
       " '48404c28-ba6a-41e4-bc46-3144bb42219d',\n",
       " 'fdfa00e0-9d10-4dc9-a392-e0a37149b98a',\n",
       " 'fd49e38d-b27e-43e6-83ae-8bcf3b5d3ba4',\n",
       " 'e493fa18-c020-4294-b13c-b13a77aef3b8',\n",
       " '4b6d5027-5928-4352-8332-7e3650c4b36d',\n",
       " '91003ba4-ad3f-4979-8cd2-7751a01bafcf',\n",
       " 'a09b1aca-5fda-4a44-bc1b-0b7a223f8a9f',\n",
       " '51d924df-65f7-4702-aad3-8865d46bb3cf',\n",
       " 'ade328c3-c02f-4fa7-9e01-9eccb1d3a830']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "class DocumentManager:\n",
    "    def __init__(self, directory_path, glob_pattern=\"./*.md\"):\n",
    "        self.directory_path = directory_path\n",
    "        self.glob_pattern = glob_pattern\n",
    "        self.documents = None\n",
    "\n",
    "    def load_documents(self):\n",
    "        loader = DirectoryLoader(\n",
    "            self.directory_path,\n",
    "            glob=self.glob_pattern,\n",
    "            show_progress=True,\n",
    "            loader_cls=UnstructuredMarkdownLoader,\n",
    "        )\n",
    "        self.documents = loader.load()\n",
    "\n",
    "    def split_documents(self, chunk_size=1000, chunk_overlap=500):\n",
    "        self.load_documents()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(self.documents)\n",
    "        logger.info(chunks)\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from loguru import logger\n",
    "from os import path\n",
    "from shutil import rmtree\n",
    "\n",
    "\n",
    "class EmbeddingManager:\n",
    "    def __init__(\n",
    "        self, chunks: list[Document] = None, ids:list = None, persist_directory=\"./chroma_langchain_dbs\", embedding=None\n",
    "    ):\n",
    "        self.chunks = chunks\n",
    "        self.ids = ids\n",
    "        self.persist_directory = persist_directory\n",
    "        self.vectordb = None\n",
    "        self.embedding = embedding or GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/text-embedding-004\"\n",
    "        )\n",
    "\n",
    "    def get_vectordb(self, **kwargs):\n",
    "        logger.info(\"Trying load the vectordb\")\n",
    "        self.vectordb = Chroma(\n",
    "           collection_name=\"chatbot_bank_service\", persist_directory=self.persist_directory, embedding_function=self.embedding\n",
    "        )\n",
    "        logger.success(\"Success load vectordb\")\n",
    "        return self.vectordb\n",
    "\n",
    "    # Method to create and persist embeddings\n",
    "    def create_and_persist_embeddings(self):\n",
    "        try:\n",
    "            if path.exists(self.persist_directory):\n",
    "                logger.info(\"Remove existent persist chroma db directory\")\n",
    "                rmtree(self.persist_directory)\n",
    "                logger.success(\"Success remove existent persist chroma db directory\")\n",
    "\n",
    "            logger.info(\n",
    "                \"Creating an instance of Chroma with the sections and the embeddings\"\n",
    "            )\n",
    "            self.vectordb = Chroma(\n",
    "                collection_name=\"chatbot_bank_service\",\n",
    "                embedding_function=self.embedding,\n",
    "                persist_directory=self.persist_directory,  # Where to save data locally, remove if not necessary\n",
    "            )\n",
    "            logger.success(\n",
    "                \"Success creating an instance of Chroma with the sections and the embeddings\"\n",
    "            )\n",
    "            logger.info(\"Adding document to vectordb\")\n",
    "            logger.info(self.chunks[0])\n",
    "            self.vectordb.add_documents(documents=self.chunks, ids = self.ids)\n",
    "            logger.success(\"Success adding document to vectordb\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-09 21:25:03.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_persist_embeddings\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mRemove existent persist chroma db directory\u001b[0m\n",
      "\u001b[32m2024-12-09 21:25:03.935\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_persist_embeddings\u001b[0m:\u001b[36m35\u001b[0m - \u001b[32m\u001b[1mSuccess remove existent persist chroma db directory\u001b[0m\n",
      "\u001b[32m2024-12-09 21:25:03.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_persist_embeddings\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mCreating an instance of Chroma with the sections and the embeddings\u001b[0m\n",
      "\u001b[32m2024-12-09 21:25:03.941\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_persist_embeddings\u001b[0m:\u001b[36m45\u001b[0m - \u001b[32m\u001b[1mSuccess creating an instance of Chroma with the sections and the embeddings\u001b[0m\n",
      "\u001b[32m2024-12-09 21:25:03.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_persist_embeddings\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mAdding document to vectordb\u001b[0m\n",
      "\u001b[32m2024-12-09 21:25:03.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_persist_embeddings\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mpage_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.' metadata={'source': 'tweet'}\u001b[0m\n",
      "\u001b[32m2024-12-09 21:25:04.555\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_persist_embeddings\u001b[0m:\u001b[36m54\u001b[0m - \u001b[31m\u001b[1mattempt to write a readonly database\u001b[0m\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
      "    └ <module 'ipykernel.kernelapp' from '/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipyker...\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "    │   └ <function IPKernelApp.start at 0x79f5195d7c40>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x79f51bff3500>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "    │    │       └ <function BaseAsyncIOLoop.start at 0x79f519618b80>\n",
      "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x79f5195ea6c0>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x79f51bff3500>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    │    │            └ <function BaseEventLoop.run_forever at 0x79f51ae64a40>\n",
      "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x79f5195ea6c0>\n",
      "  File \"/home/pradanaend/.pyenv/versions/3.12.6/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "    │    └ <function BaseEventLoop._run_once at 0x79f51ae66840>\n",
      "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "  File \"/home/pradanaend/.pyenv/versions/3.12.6/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "    │      └ <function Handle._run at 0x79f51afe6ca0>\n",
      "    └ <Handle Task.task_wakeup(<Future finis...2B)>, ...],))>)>\n",
      "  File \"/home/pradanaend/.pyenv/versions/3.12.6/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    │    │            │    │           │    └ <member '_args' of 'Handle' objects>\n",
      "    │    │            │    │           └ <Handle Task.task_wakeup(<Future finis...2B)>, ...],))>)>\n",
      "    │    │            │    └ <member '_callback' of 'Handle' objects>\n",
      "    │    │            └ <Handle Task.task_wakeup(<Future finis...2B)>, ...],))>)>\n",
      "    │    └ <member '_context' of 'Handle' objects>\n",
      "    └ <Handle Task.task_wakeup(<Future finis...2B)>, ...],))>)>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "          │    └ <function Kernel.process_one at 0x79f51978b2e0>\n",
      "          └ <ipykernel.ipkernel.IPythonKernel object at 0x79f5195e9f10>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "          │         └ ([<zmq.Frame(b'87009fc9-258'...36B)>, <zmq.Frame(b'<IDS|MSG>')>, <zmq.Frame(b'5d328066c6bb'...64B)>, <zmq.Frame(b'{\"date\":\"20...\n",
      "          └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x79f5195e9f10>>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "          └ <coroutine object IPythonKernel.execute_request at 0x79f4b433af40>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "                                  │       │      └ {'header': {'date': datetime.datetime(2024, 12, 9, 13, 25, 3, 928000, tzinfo=tzutc()), 'msg_id': '43d68745-d90c-4754-9cf8-6b4...\n",
      "                                  │       └ [b'87009fc9-258c-4d23-9f9f-38406d100c69']\n",
      "                                  └ <zmq.eventloop.zmqstream.ZMQStream object at 0x79f5195ea9f0>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "                          └ <coroutine object IPythonKernel.do_execute at 0x79f518382740>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "          │     └ <function ZMQInteractiveShell.run_cell at 0x79f5195cb7e0>\n",
      "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79f5107bec60>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "                             │       └ {'store_history': True, 'silent': False, 'cell_id': 'vscode-notebook-cell:/home/pradanaend/Documents/Project/chatbot-bank/not...\n",
      "                             └ ('embedding_manager = EmbeddingManager(chunks= documents, ids=uuids)\\nembedding_manager.create_and_persist_embeddings()\\n',)\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "             │    └ <function InteractiveShell._run_cell at 0x79f51a2d1760>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79f5107bec60>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "             │      └ <coroutine object InteractiveShell.run_cell_async at 0x79f4aa487240>\n",
      "             └ <function _pseudo_sync_runner at 0x79f51a2c8900>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    │    └ <method 'send' of 'coroutine' objects>\n",
      "    └ <coroutine object InteractiveShell.run_cell_async at 0x79f4aa487240>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "                       │    │             │        │     └ '/tmp/ipykernel_504724/2003596091.py'\n",
      "                       │    │             │        └ [<ast.Assign object at 0x79f4d4681bd0>, <ast.Expr object at 0x79f49c929450>]\n",
      "                       │    │             └ <ast.Module object at 0x79f4d4682490>\n",
      "                       │    └ <function InteractiveShell.run_ast_nodes at 0x79f51a2d1a80>\n",
      "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79f5107bec60>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "             │    │        │     │              └ False\n",
      "             │    │        │     └ <ExecutionResult object at 79f49edd7200, execution_count=42 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...\n",
      "             │    │        └ <code object <module> at 0x79f493b45020, file \"/tmp/ipykernel_504724/2003596091.py\", line 1>\n",
      "             │    └ <function InteractiveShell.run_code at 0x79f51a2d1b20>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79f5107bec60>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "         │         │    │               │    └ {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...\n",
      "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79f5107bec60>\n",
      "         │         │    └ <property object at 0x79f51a2c54e0>\n",
      "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x79f5107bec60>\n",
      "         └ <code object <module> at 0x79f493b45020, file \"/tmp/ipykernel_504724/2003596091.py\", line 1>\n",
      "\n",
      "  File \"\u001b[32m/tmp/ipykernel_504724/\u001b[0m\u001b[32m\u001b[1m2003596091.py\u001b[0m\", line \u001b[33m2\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1membedding_manager\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mcreate_and_persist_embeddings\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│                 └ \u001b[0m\u001b[36m\u001b[1m<function EmbeddingManager.create_and_persist_embeddings at 0x79f49ca93e20>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<__main__.EmbeddingManager object at 0x79f4b440ac30>\u001b[0m\n",
      "\n",
      "> File \"\u001b[32m/tmp/ipykernel_504724/\u001b[0m\u001b[32m\u001b[1m3978043461.py\u001b[0m\", line \u001b[33m50\u001b[0m, in \u001b[35mcreate_and_persist_embeddings\u001b[0m\n",
      "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mvectordb\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1madd_documents\u001b[0m\u001b[1m(\u001b[0m\u001b[1mdocuments\u001b[0m\u001b[35m\u001b[1m=\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mchunks\u001b[0m\u001b[1m,\u001b[0m \u001b[1mids\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mids\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│    │        │                       │    │             │    └ \u001b[0m\u001b[36m\u001b[1m['0312f322-05fe-46d1-adb0-72dda5f187c8', '48404c28-ba6a-41e4-bc46-3144bb42219d', 'fdfa00e0-9d10-4dc9-a392-e0a37149b98a', 'fd4...\u001b[0m\n",
      "    \u001b[36m│    │        │                       │    │             └ \u001b[0m\u001b[36m\u001b[1m<__main__.EmbeddingManager object at 0x79f4b440ac30>\u001b[0m\n",
      "    \u001b[36m│    │        │                       │    └ \u001b[0m\u001b[36m\u001b[1m[Document(id='1', metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast ...\u001b[0m\n",
      "    \u001b[36m│    │        │                       └ \u001b[0m\u001b[36m\u001b[1m<__main__.EmbeddingManager object at 0x79f4b440ac30>\u001b[0m\n",
      "    \u001b[36m│    │        └ \u001b[0m\u001b[36m\u001b[1m<function VectorStore.add_documents at 0x79f4e46b3560>\u001b[0m\n",
      "    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<langchain_chroma.vectorstores.Chroma object at 0x79f4b42abe30>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<__main__.EmbeddingManager object at 0x79f4b440ac30>\u001b[0m\n",
      "\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py\", line 287, in add_documents\n",
      "    return self.add_texts(texts, metadatas, **kwargs)\n",
      "           │    │         │      │            └ {'ids': ['0312f322-05fe-46d1-adb0-72dda5f187c8', '48404c28-ba6a-41e4-bc46-3144bb42219d', 'fdfa00e0-9d10-4dc9-a392-e0a37149b98...\n",
      "           │    │         │      └ [{'source': 'tweet'}, {'source': 'news'}, {'source': 'tweet'}, {'source': 'news'}, {'source': 'tweet'}, {'source': 'website'}...\n",
      "           │    │         └ ['I had chocolate chip pancakes and scrambled eggs for breakfast this morning.', 'The weather forecast for tomorrow is cloudy...\n",
      "           │    └ <function Chroma.add_texts at 0x79f4e40bcae0>\n",
      "           └ <langchain_chroma.vectorstores.Chroma object at 0x79f4b42abe30>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 530, in add_texts\n",
      "    self._collection.upsert(\n",
      "    │    └ <property object at 0x79f4e4468130>\n",
      "    └ <langchain_chroma.vectorstores.Chroma object at 0x79f4b42abe30>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/chromadb/api/models/Collection.py\", line 343, in upsert\n",
      "    self._client._upsert(\n",
      "    │    │       └ <function SegmentAPI._upsert at 0x79f4d4717060>\n",
      "    │    └ <chromadb.api.segment.SegmentAPI object at 0x79f49ede1c40>\n",
      "    └ Collection(name=chatbot_bank_service)\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py\", line 150, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           │  │       └ {'collection_id': UUID('f9d87066-7098-4ac3-a268-dd46d721974e'), 'ids': ['0312f322-05fe-46d1-adb0-72dda5f187c8', '48404c28-ba6...\n",
      "           │  └ (<chromadb.api.segment.SegmentAPI object at 0x79f49ede1c40>,)\n",
      "           └ <function SegmentAPI._upsert at 0x79f4d4716fc0>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/chromadb/api/segment.py\", line 103, in wrapper\n",
      "    return self._rate_limit_enforcer.rate_limit(func)(*args, **kwargs)\n",
      "           │    │                    │          │      │       └ {'collection_id': UUID('f9d87066-7098-4ac3-a268-dd46d721974e'), 'ids': ['0312f322-05fe-46d1-adb0-72dda5f187c8', '48404c28-ba6...\n",
      "           │    │                    │          │      └ (<chromadb.api.segment.SegmentAPI object at 0x79f49ede1c40>,)\n",
      "           │    │                    │          └ <function SegmentAPI._upsert at 0x79f4d4716f20>\n",
      "           │    │                    └ <function SimpleRateLimitEnforcer.rate_limit at 0x79f4d46a0f40>\n",
      "           │    └ <chromadb.rate_limit.simple_rate_limit.SimpleRateLimitEnforcer object at 0x79f49ede1670>\n",
      "           └ <chromadb.api.segment.SegmentAPI object at 0x79f49ede1c40>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/chromadb/rate_limit/simple_rate_limit/__init__.py\", line 23, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           │     │       └ {'collection_id': UUID('f9d87066-7098-4ac3-a268-dd46d721974e'), 'ids': ['0312f322-05fe-46d1-adb0-72dda5f187c8', '48404c28-ba6...\n",
      "           │     └ (<chromadb.api.segment.SegmentAPI object at 0x79f49ede1c40>,)\n",
      "           └ <function SegmentAPI._upsert at 0x79f4d4716f20>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/chromadb/api/segment.py\", line 548, in _upsert\n",
      "    self._producer.submit_embeddings(collection_id, records_to_submit)\n",
      "    │    │         │                 │              └ [{'id': '0312f322-05fe-46d1-adb0-72dda5f187c8', 'embedding': array([ 1.09146871e-02, -2.41428837e-02, -2.79461406e-02, -1.332...\n",
      "    │    │         │                 └ UUID('f9d87066-7098-4ac3-a268-dd46d721974e')\n",
      "    │    │         └ <function SqlEmbeddingsQueue.submit_embeddings at 0x79f4d463e8e0>\n",
      "    │    └ <chromadb.db.impl.sqlite.SqliteDB object at 0x79f49ede0350>\n",
      "    └ <chromadb.api.segment.SegmentAPI object at 0x79f49ede1c40>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py\", line 150, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           │  │       └ {}\n",
      "           │  └ (<chromadb.db.impl.sqlite.SqliteDB object at 0x79f49ede0350>, UUID('f9d87066-7098-4ac3-a268-dd46d721974e'), [{'id': '0312f322...\n",
      "           └ <function SqlEmbeddingsQueue.submit_embeddings at 0x79f4d463e840>\n",
      "  File \"/home/pradanaend/Documents/Project/chatbot-bank/.venv/lib/python3.12/site-packages/chromadb/db/mixins/embeddings_queue.py\", line 243, in submit_embeddings\n",
      "    results = cur.execute(sql, params).fetchall()\n",
      "              │   │       │    └ (2, 'persistent://default/default/f9d87066-7098-4ac3-a268-dd46d721974e', '0312f322-05fe-46d1-adb0-72dda5f187c8', b'\\x84\\xd32<...\n",
      "              │   │       └ 'INSERT INTO \"embeddings_queue\" (\"operation\",\"topic\",\"id\",\"vector\",\"encoding\",\"metadata\") VALUES (?,?,?,?,?,?),(?,?,?,?,?,?),...\n",
      "              │   └ <method 'execute' of 'sqlite3.Cursor' objects>\n",
      "              └ <sqlite3.Cursor object at 0x79f493b531c0>\n",
      "\n",
      "\u001b[31m\u001b[1msqlite3.OperationalError\u001b[0m:\u001b[1m attempt to write a readonly database\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "embedding_manager = EmbeddingManager(chunks= documents, ids=uuids)\n",
    "embedding_manager.create_and_persist_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-09 21:25:07.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_vectordb\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mTrying load the vectordb\u001b[0m\n",
      "\u001b[32m2024-12-09 21:25:07.898\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_vectordb\u001b[0m:\u001b[36m26\u001b[0m - \u001b[32m\u001b[1mSuccess load vectordb\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': ['0312f322-05fe-46d1-adb0-72dda5f187c8',\n",
       "  '48404c28-ba6a-41e4-bc46-3144bb42219d',\n",
       "  'fdfa00e0-9d10-4dc9-a392-e0a37149b98a',\n",
       "  'fd49e38d-b27e-43e6-83ae-8bcf3b5d3ba4',\n",
       "  'e493fa18-c020-4294-b13c-b13a77aef3b8',\n",
       "  '4b6d5027-5928-4352-8332-7e3650c4b36d',\n",
       "  '91003ba4-ad3f-4979-8cd2-7751a01bafcf',\n",
       "  'a09b1aca-5fda-4a44-bc1b-0b7a223f8a9f',\n",
       "  '51d924df-65f7-4702-aad3-8865d46bb3cf',\n",
       "  'ade328c3-c02f-4fa7-9e01-9eccb1d3a830'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['I had chocolate chip pancakes and scrambled eggs for breakfast this morning.',\n",
       "  'The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.',\n",
       "  'Building an exciting new project with LangChain - come check it out!',\n",
       "  'Robbers broke into the city bank and stole $1 million in cash.',\n",
       "  \"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
       "  'Is the new iPhone worth the price? Read this review to find out.',\n",
       "  'The top 10 soccer players in the world right now.',\n",
       "  'LangGraph is the best framework for building stateful, agentic applications!',\n",
       "  'The stock market is down 500 points today due to fears of a recession.',\n",
       "  'I have a bad feeling I am going to get deleted :('],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_manager.get_vectordb().get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
